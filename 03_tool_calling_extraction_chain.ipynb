{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f873b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034cb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env vars\n",
    "load_dotenv(\"./.env\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"tool_calling_extraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f34762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Computer(BaseModel):\n",
    "    \"\"\"Specifications of any computing device\"\"\"\n",
    "\n",
    "    model: Optional[str] = Field(\n",
    "        description=\"The specific model number or name of the computing device.\"\n",
    "    )\n",
    "    storage: Optional[int] = Field(\n",
    "        description=\"How many GBs the computng device has as the total storage.\"\n",
    "    )\n",
    "    num_cpu: Optional[int] = Field(\n",
    "        description=\"The number of physical CPUs the device has.\", ge=1\n",
    "    )\n",
    "    gpus: Optional[list[str]] = Field(\n",
    "        description=\"The graphics processing units the comuting device has.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert information extraction machine. Only extract relevant, accurat and true information from the input. If you don't know the value of an attribute you are asked to extract, you can return None. Don't make up information you don't know.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44016951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up structured output\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(model=\"gpt-5\", model_provider=\"openai\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=Computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer(model='Lenovo ThinkStation', storage=None, num_cpu=None, gpus=['NVIDIA GPU', 'Intel iGPU'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run inference\n",
    "text = \"I'm looking to upgrade my intel dual core proecssor. It's nvidia gpu is getting bottlenecked by the weak igpu. It's an old Lenovo thinkstation.\"\n",
    "prompt = prompt_template.invoke(input={\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b357ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data from multiple entities\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about computers\"\"\"\n",
    "\n",
    "    computers: list[Computer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a23bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(computers=[Computer(model='Acer Predator Helios 300', storage=1000, num_cpu=1, gpus=['NVIDIA GeForce RTX 3070']), Computer(model='Apple MacBook Pro M2', storage=512, num_cpu=None, gpus=['Apple M2 GPU']), Computer(model='Dell Precision 7865', storage=2000, num_cpu=2, gpus=['NVIDIA RTX A6000', 'Intel UHD Graphics 770']), Computer(model='Lenovo IdeaPad 3', storage=256, num_cpu=1, gpus=None), Computer(model='ZBox QX', storage=1000, num_cpu=1, gpus=['NVIDIA Quadro P5000'])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run inference for multiple entities\n",
    "multiple_computer_text = \"\"\"At the tech expo, several new computing devices were showcased.\n",
    "\n",
    "First, the Acer Predator Helios 300 was on display, boasting 1TB of SSD storage, 1 CPU, and an NVIDIA GeForce RTX 3070 GPU.\n",
    "\n",
    "Next was the Apple MacBook Pro M2, which includes 512GB of storage and the Apple M2 GPU, but details about the number of CPUs weren't provided.\n",
    "\n",
    "Dell presented a workstation, model Dell Precision 7865, equipped with 2 CPUs, 2TB of storage, and two GPUs: NVIDIA RTX A6000 and Intel UHD Graphics 770.\n",
    "\n",
    "A budget laptop labeled Lenovo IdeaPad 3 came with 256GB storage and 1 CPU, but no GPU was listed.\n",
    "\n",
    "Finally, there was a compact mini-PC, simply called ZBox QX, which runs with 1 CPU, 1TB of storage, and an NVIDIA Quadro P5000 GPU.\"\"\"\n",
    "\n",
    "multiple_entity_prompt = prompt_template.invoke(input={\"text\": multiple_computer_text})\n",
    "multiple_entity_structured_llm = llm.with_structured_output(schema=Data)\n",
    "multiple_entity_structured_llm.invoke(multiple_entity_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66acee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='30', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 266, 'prompt_tokens': 46, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-C4OXQiHqO9VwWMNfNqmh2FuvSIMsj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dcb4c7d3-4caa-46d5-835b-96cd12872c87-0', usage_metadata={'input_tokens': 46, 'output_tokens': 266, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# few shot example\n",
    "\n",
    "mesages = [\n",
    "    (\"human\", \"1 üèÄ 2\"),\n",
    "    (\"ai\", \"2\"),\n",
    "    (\"human\", \"3 üèÄ 4\"),\n",
    "    (\"ai\", \"12\"),\n",
    "    (\"human\", \"5 üèÄ 6\"),\n",
    "]\n",
    "llm.invoke(mesages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d108b6",
   "metadata": {},
   "source": [
    "- Structured output uses tool calling at a low level, using the Pydantic schema to verify the output\n",
    "- Some model providers require an ai message after the tool call\n",
    "- The `tool_example_to_messages` will do this for us according to the model provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11cf435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150106/1444525344.py:32: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n",
      "  tool_example_to_messages(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"The Bajaj Pulsar N160 boasts dual abs breaks and a 160cc engine, all complimented by the telescopic suspension on the front and the back.\",\n",
    "        Data(computers=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"I'm looking to upgrade my intel dual core proecssor. It's nvidia gpu is getting bottlenecked by the weak igpu. It's an old Lenovo thinkstation.\",\n",
    "        Data(\n",
    "            computers=[\n",
    "                Computer(\n",
    "                    model=\"Lenovo ThinkStation\",\n",
    "                    storage=None,\n",
    "                    num_cpu=1,\n",
    "                    gpus=[\"NVIDIA GPU\"],\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "messages: list[BaseMessage] = []\n",
    "\n",
    "for input_text, tool_call in examples:\n",
    "    if tool_call.computers:\n",
    "        ai_message = \"Computer info extracted!\"\n",
    "    else:\n",
    "        ai_message = \"No computers detected!\"\n",
    "    messages.extend(\n",
    "        tool_example_to_messages(\n",
    "            input=input_text, tool_calls=[tool_call], ai_response=ai_message\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385d7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The Bajaj Pulsar N160 boasts dual abs breaks and a 160cc engine, all complimented by the telescopic suspension on the front and the back.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (7b856892-e79d-40a1-a5cf-13de82c23f2a)\n",
      " Call ID: 7b856892-e79d-40a1-a5cf-13de82c23f2a\n",
      "  Args:\n",
      "    computers: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "No computers detected!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to upgrade my intel dual core proecssor. It's nvidia gpu is getting bottlenecked by the weak igpu. It's an old Lenovo thinkstation.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (fe46f225-2f9b-4f7f-814e-1aa2d2b0046c)\n",
      " Call ID: fe46f225-2f9b-4f7f-814e-1aa2d2b0046c\n",
      "  Args:\n",
      "    computers: [{'model': 'Lenovo ThinkStation', 'storage': None, 'num_cpu': 1, 'gpus': ['NVIDIA GPU']}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Computer info extracted!\n"
     ]
    }
   ],
   "source": [
    "for i in messages:\n",
    "    i.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea4a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template with few-shot examples\n",
    "base_messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an expert information extraction machine. Only extract relevant, accurat and true information from the input. If you don't know the value of an attribute you are asked to extract, you can return None. Don't make up information you don't know.\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add the few-shot examples\n",
    "base_messages.extend(messages)\n",
    "\n",
    "# Add the final human input\n",
    "base_messages.append((\"human\", \"{text}\"))\n",
    "\n",
    "# Create the new prompt template\n",
    "few_shot_prompt_template = ChatPromptTemplate.from_messages(base_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c892581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(computers=[Computer(model='Dell XPS 15', storage=512, num_cpu=None, gpus=['NVIDIA GTX 1650'])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the few-shot prompt template\n",
    "test_text = (\n",
    "    \"I have a Dell XPS 15 with 16GB RAM, 512GB SSD, and NVIDIA GTX 1650 graphics card.\"\n",
    ")\n",
    "\n",
    "system_message = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert information extraction machine. Only extract relevant, accurat and true information from the input. If you don't know the value of an attribute you are asked to extract, you can return None. Don't make up information you don't know.\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "few_shot_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message + messages + [(\"human\", \"{input}\")]]\n",
    ")\n",
    "few_shot_prompt_template = few_shot_prompt_template.invoke(input={\"input\": test_text})\n",
    "multiple_entity_structured_llm.invoke(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f381df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an expert information extraction machine. Only extract relevant, accurat and true information from the input. If you don't know the value of an attribute you are asked to extract, you can return None. Don't make up information you don't know.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The Bajaj Pulsar N160 boasts dual abs breaks and a 160cc engine, all complimented by the telescopic suspension on the front and the back.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (7b856892-e79d-40a1-a5cf-13de82c23f2a)\n",
      " Call ID: 7b856892-e79d-40a1-a5cf-13de82c23f2a\n",
      "  Args:\n",
      "    computers: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "No computers detected!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to upgrade my intel dual core proecssor. It's nvidia gpu is getting bottlenecked by the weak igpu. It's an old Lenovo thinkstation.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (fe46f225-2f9b-4f7f-814e-1aa2d2b0046c)\n",
      " Call ID: fe46f225-2f9b-4f7f-814e-1aa2d2b0046c\n",
      "  Args:\n",
      "    computers: [{'model': 'Lenovo ThinkStation', 'storage': None, 'num_cpu': 1, 'gpus': ['NVIDIA GPU']}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Computer info extracted!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have a Dell XPS 15 with 16GB RAM, 512GB SSD, and NVIDIA GTX 1650 graphics card.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pp\n",
    "\n",
    "for i in few_shot_prompt_template.__dict__.get(\"messages\"):\n",
    "    i.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-wth-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
