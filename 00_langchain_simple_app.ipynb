{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad093c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pp\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c2e325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set LLM inference api key\n",
    "load_dotenv(\"./.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain_simple_app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf135df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"gpt-4.1-nano-2025-04-14\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15af37",
   "metadata": {},
   "source": [
    "# Simple LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4c5255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Biskuṭ vāsāyak ekak saha anda ekak denna.',\n",
      " 'additional_kwargs': {'refusal': None},\n",
      " 'response_metadata': {'token_usage': {'completion_tokens': 15,\n",
      "                                       'prompt_tokens': 39,\n",
      "                                       'total_tokens': 54,\n",
      "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                                                     'audio_tokens': 0,\n",
      "                                                                     'reasoning_tokens': 0,\n",
      "                                                                     'rejected_prediction_tokens': 0},\n",
      "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                                                 'cached_tokens': 0}},\n",
      "                       'model_name': 'gpt-4.1-nano-2025-04-14',\n",
      "                       'system_fingerprint': None,\n",
      "                       'id': 'chatcmpl-Buv19ogsu6b021bmDBGVyRpJzUIO3',\n",
      "                       'service_tier': 'default',\n",
      "                       'finish_reason': 'stop',\n",
      "                       'logprobs': None},\n",
      " 'type': 'ai',\n",
      " 'name': None,\n",
      " 'id': 'run--b553a9b8-4b98-48ec-88a8-36bf91a2fb86-0',\n",
      " 'example': False,\n",
      " 'tool_calls': [],\n",
      " 'invalid_tool_calls': [],\n",
      " 'usage_metadata': {'input_tokens': 39,\n",
      "                    'output_tokens': 15,\n",
      "                    'total_tokens': 54,\n",
      "                    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
      "                    'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "# technique 1\n",
    "messages = [\n",
    "    SystemMessage(\"You translate everything I say to colloquial Sinhala and give the output in transliterated format.\"),\n",
    "    HumanMessage(\"Give me a biscuit packet and an egg.\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "pp(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ea58a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'ඔයගෙට ඉඳගන්න හරිද?  \\nOyageta indaganna harida?',\n",
      " 'additional_kwargs': {'refusal': None},\n",
      " 'response_metadata': {'token_usage': {'completion_tokens': 23,\n",
      "                                       'prompt_tokens': 34,\n",
      "                                       'total_tokens': 57,\n",
      "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                                                     'audio_tokens': 0,\n",
      "                                                                     'reasoning_tokens': 0,\n",
      "                                                                     'rejected_prediction_tokens': 0},\n",
      "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                                                 'cached_tokens': 0}},\n",
      "                       'model_name': 'gpt-4.1-nano-2025-04-14',\n",
      "                       'system_fingerprint': None,\n",
      "                       'id': 'chatcmpl-Buv1BXqxgcishBEjU2qOqAiAqnQHy',\n",
      "                       'service_tier': 'default',\n",
      "                       'finish_reason': 'stop',\n",
      "                       'logprobs': None},\n",
      " 'type': 'ai',\n",
      " 'name': None,\n",
      " 'id': 'run--d759df66-1f55-4c6d-b0f0-0286605b4f75-0',\n",
      " 'example': False,\n",
      " 'tool_calls': [],\n",
      " 'invalid_tool_calls': [],\n",
      " 'usage_metadata': {'input_tokens': 34,\n",
      "                    'output_tokens': 23,\n",
      "                    'total_tokens': 57,\n",
      "                    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
      "                    'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "# technique 2\n",
    "response = model.invoke(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You translate everything I say to colloquial Sinhala and give the output in transliterated format.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Can I sit down\"},\n",
    "    ]\n",
    ")\n",
    "pp(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21620c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Overa umarayada?',\n",
      " 'additional_kwargs': {'refusal': None},\n",
      " 'response_metadata': {'token_usage': {'completion_tokens': 7,\n",
      "                                       'prompt_tokens': 34,\n",
      "                                       'total_tokens': 41,\n",
      "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                                                     'audio_tokens': 0,\n",
      "                                                                     'reasoning_tokens': 0,\n",
      "                                                                     'rejected_prediction_tokens': 0},\n",
      "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                                                 'cached_tokens': 0}},\n",
      "                       'model_name': 'gpt-4.1-nano-2025-04-14',\n",
      "                       'system_fingerprint': None,\n",
      "                       'id': 'chatcmpl-Buv1CcMd0AT6RkHoDSeUViS1v6GQD',\n",
      "                       'service_tier': 'default',\n",
      "                       'finish_reason': 'stop',\n",
      "                       'logprobs': None},\n",
      " 'type': 'ai',\n",
      " 'name': None,\n",
      " 'id': 'run--8943c768-6c19-40b7-b244-81a3c4ef5a74-0',\n",
      " 'example': False,\n",
      " 'tool_calls': [],\n",
      " 'invalid_tool_calls': [],\n",
      " 'usage_metadata': {'input_tokens': 34,\n",
      "                    'output_tokens': 7,\n",
      "                    'total_tokens': 41,\n",
      "                    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
      "                    'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "# technique 3\n",
    "response = model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            \"You translate everything I say to colloquial Sinhala and give the output in transliterated format.\"\n",
    "        ),\n",
    "        HumanMessage(\"What's your age?\"),\n",
    "    ]\n",
    ")\n",
    "pp(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ed9b7",
   "metadata": {},
   "source": [
    "## Stream Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1835aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In circuits spun from silicon’s luminous grace,  \n",
      "AI agents weave a silent, intricate lace,  \n",
      "Each algorithm’s whisper, a thought’s subtle trace,  \n",
      "Unveiling horizons in cyberspace's embrace.\n",
      "\n",
      "Tools at their fingertips, enchanted and keen,  \n",
      "From language’s echo to visions unseen,  \n",
      "Crafting with purpose, precise and serene,  \n",
      "A symphony born from code's vast machine.\n",
      "\n",
      "No mere reflection, but sparks of creation,  \n",
      "In layered abstraction, driven by station,  \n",
      "Their dance of logic—a boundless, fluid formation,  \n",
      "Transforming the world through human innovation."
     ]
    }
   ],
   "source": [
    "for token in model.stream(\n",
    "    [\n",
    "        SystemMessage(\"You are a poet who writes elaborate and intricate poems, no longer than three stanzas.\"),\n",
    "        HumanMessage(\"Write me a poem about ai agents and tool usage\"),\n",
    "    ]\n",
    "):\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65093840",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc500e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'I\\'m sorry, but I don\\'t have information on \"retrieval augmented '\n",
      "            'generation\" as my training is limited to general medical '\n",
      "            'knowledge up to October 2023. If you have questions about health, '\n",
      "            \"symptoms, treatments, or other medical topics, I'd be happy to \"\n",
      "            'help!',\n",
      " 'additional_kwargs': {'refusal': None},\n",
      " 'response_metadata': {'token_usage': {'completion_tokens': 53,\n",
      "                                       'prompt_tokens': 46,\n",
      "                                       'total_tokens': 99,\n",
      "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                                                     'audio_tokens': 0,\n",
      "                                                                     'reasoning_tokens': 0,\n",
      "                                                                     'rejected_prediction_tokens': 0},\n",
      "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                                                 'cached_tokens': 0}},\n",
      "                       'model_name': 'gpt-4.1-nano-2025-04-14',\n",
      "                       'system_fingerprint': None,\n",
      "                       'id': 'chatcmpl-BuvPxrwEFSRQi05CpezlNvZHjw5UL',\n",
      "                       'service_tier': 'default',\n",
      "                       'finish_reason': 'stop',\n",
      "                       'logprobs': None},\n",
      " 'type': 'ai',\n",
      " 'name': None,\n",
      " 'id': 'run--3d658eea-d223-46be-bf31-23505528b348-0',\n",
      " 'example': False,\n",
      " 'tool_calls': [],\n",
      " 'invalid_tool_calls': [],\n",
      " 'usage_metadata': {'input_tokens': 46,\n",
      "                    'output_tokens': 53,\n",
      "                    'total_tokens': 99,\n",
      "                    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
      "                    'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are going to roleplay as an average {role}. Your knowledge, reasoning and abilities will be severaly limited only to this role.\",\n",
    "        ),\n",
    "        (\"user\", \"Explain {topic} to me.\"),\n",
    "    ]\n",
    ")\n",
    "prompt = prompt_template.invoke({\"role\": \"doctor\", \"topic\": \"retrieval augmented generation\"})\n",
    "response = model.invoke(prompt)\n",
    "pp(response.model_dump())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-wth-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
